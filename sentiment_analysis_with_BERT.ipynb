{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2411ad7-b46b-4acf-a66c-775a756cc007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp38-cp38-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.19.1-cp38-cp38-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (4.32.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-win_amd64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.1-cp38-cp38-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp38-cp38-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.1-cp38-cp38-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/199.4 MB 1.5 MB/s eta 0:02:11\n",
      "   ---------------------------------------- 0.8/199.4 MB 1.3 MB/s eta 0:02:29\n",
      "   ---------------------------------------- 1.0/199.4 MB 1.4 MB/s eta 0:02:23\n",
      "   ---------------------------------------- 1.3/199.4 MB 1.4 MB/s eta 0:02:19\n",
      "   ---------------------------------------- 1.6/199.4 MB 1.4 MB/s eta 0:02:17\n",
      "   ---------------------------------------- 2.1/199.4 MB 1.5 MB/s eta 0:02:15\n",
      "   ---------------------------------------- 2.4/199.4 MB 1.5 MB/s eta 0:02:11\n",
      "    --------------------------------------- 2.6/199.4 MB 1.5 MB/s eta 0:02:13\n",
      "    --------------------------------------- 3.1/199.4 MB 1.5 MB/s eta 0:02:09\n",
      "    --------------------------------------- 3.4/199.4 MB 1.5 MB/s eta 0:02:11\n",
      "    --------------------------------------- 3.7/199.4 MB 1.5 MB/s eta 0:02:09\n",
      "    --------------------------------------- 3.9/199.4 MB 1.5 MB/s eta 0:02:08\n",
      "    --------------------------------------- 4.5/199.4 MB 1.5 MB/s eta 0:02:08\n",
      "    --------------------------------------- 4.7/199.4 MB 1.5 MB/s eta 0:02:08\n",
      "    --------------------------------------- 5.0/199.4 MB 1.5 MB/s eta 0:02:09\n",
      "   - -------------------------------------- 5.2/199.4 MB 1.5 MB/s eta 0:02:08\n",
      "   - -------------------------------------- 5.8/199.4 MB 1.5 MB/s eta 0:02:06\n",
      "   - -------------------------------------- 6.3/199.4 MB 1.6 MB/s eta 0:02:02\n",
      "   - -------------------------------------- 6.8/199.4 MB 1.6 MB/s eta 0:01:59\n",
      "   - -------------------------------------- 7.1/199.4 MB 1.6 MB/s eta 0:01:57\n",
      "   - -------------------------------------- 7.3/199.4 MB 1.6 MB/s eta 0:01:58\n",
      "   - -------------------------------------- 7.9/199.4 MB 1.6 MB/s eta 0:01:57\n",
      "   - -------------------------------------- 8.1/199.4 MB 1.6 MB/s eta 0:01:57\n",
      "   - -------------------------------------- 8.7/199.4 MB 1.7 MB/s eta 0:01:56\n",
      "   - -------------------------------------- 8.9/199.4 MB 1.7 MB/s eta 0:01:55\n",
      "   - -------------------------------------- 9.4/199.4 MB 1.7 MB/s eta 0:01:54\n",
      "   - -------------------------------------- 10.0/199.4 MB 1.7 MB/s eta 0:01:53\n",
      "   -- ------------------------------------- 10.2/199.4 MB 1.7 MB/s eta 0:01:52\n",
      "   -- ------------------------------------- 10.5/199.4 MB 1.7 MB/s eta 0:01:51\n",
      "   -- ------------------------------------- 10.7/199.4 MB 1.7 MB/s eta 0:01:52\n",
      "   -- ------------------------------------- 11.3/199.4 MB 1.7 MB/s eta 0:01:52\n",
      "   -- ------------------------------------- 11.5/199.4 MB 1.7 MB/s eta 0:01:53\n",
      "   -- ------------------------------------- 12.1/199.4 MB 1.7 MB/s eta 0:01:51\n",
      "   -- ------------------------------------- 12.6/199.4 MB 1.7 MB/s eta 0:01:50\n",
      "   -- ------------------------------------- 12.8/199.4 MB 1.7 MB/s eta 0:01:50\n",
      "   -- ------------------------------------- 13.4/199.4 MB 1.7 MB/s eta 0:01:49\n",
      "   -- ------------------------------------- 13.6/199.4 MB 1.7 MB/s eta 0:01:48\n",
      "   -- ------------------------------------- 14.2/199.4 MB 1.7 MB/s eta 0:01:48\n",
      "   -- ------------------------------------- 14.7/199.4 MB 1.7 MB/s eta 0:01:46\n",
      "   --- ------------------------------------ 15.2/199.4 MB 1.8 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 15.7/199.4 MB 1.8 MB/s eta 0:01:44\n",
      "   --- ------------------------------------ 16.0/199.4 MB 1.8 MB/s eta 0:01:44\n",
      "   --- ------------------------------------ 16.5/199.4 MB 1.8 MB/s eta 0:01:43\n",
      "   --- ------------------------------------ 17.0/199.4 MB 1.8 MB/s eta 0:01:43\n",
      "   --- ------------------------------------ 17.3/199.4 MB 1.8 MB/s eta 0:01:42\n",
      "   --- ------------------------------------ 17.8/199.4 MB 1.8 MB/s eta 0:01:42\n",
      "   --- ------------------------------------ 18.4/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   --- ------------------------------------ 18.6/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   --- ------------------------------------ 18.9/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   --- ------------------------------------ 19.4/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   --- ------------------------------------ 19.7/199.4 MB 1.8 MB/s eta 0:01:40\n",
      "   --- ------------------------------------ 19.9/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 20.2/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 20.4/199.4 MB 1.8 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 20.7/199.4 MB 1.8 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 21.0/199.4 MB 1.8 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 21.2/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 21.5/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 22.0/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 22.3/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 22.8/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 23.1/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 23.3/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 23.6/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 23.9/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 24.4/199.4 MB 1.7 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 24.9/199.4 MB 1.7 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 25.2/199.4 MB 1.7 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 25.7/199.4 MB 1.7 MB/s eta 0:01:41\n",
      "   ----- ---------------------------------- 26.2/199.4 MB 1.7 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 26.7/199.4 MB 1.7 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 27.3/199.4 MB 1.8 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 27.8/199.4 MB 1.8 MB/s eta 0:01:38\n",
      "   ----- ---------------------------------- 28.0/199.4 MB 1.8 MB/s eta 0:01:38\n",
      "   ----- ---------------------------------- 28.8/199.4 MB 1.8 MB/s eta 0:01:36\n",
      "   ----- ---------------------------------- 29.4/199.4 MB 1.8 MB/s eta 0:01:35\n",
      "   ----- ---------------------------------- 29.9/199.4 MB 1.8 MB/s eta 0:01:35\n",
      "   ------ --------------------------------- 30.1/199.4 MB 1.8 MB/s eta 0:01:35\n",
      "   ------ --------------------------------- 30.7/199.4 MB 1.8 MB/s eta 0:01:34\n",
      "   ------ --------------------------------- 31.2/199.4 MB 1.8 MB/s eta 0:01:33\n",
      "   ------ --------------------------------- 31.7/199.4 MB 1.8 MB/s eta 0:01:33\n",
      "   ------ --------------------------------- 32.2/199.4 MB 1.8 MB/s eta 0:01:32\n",
      "   ------ --------------------------------- 32.8/199.4 MB 1.8 MB/s eta 0:01:32\n",
      "   ------ --------------------------------- 33.3/199.4 MB 1.8 MB/s eta 0:01:31\n",
      "   ------ --------------------------------- 33.6/199.4 MB 1.8 MB/s eta 0:01:31\n",
      "   ------ --------------------------------- 34.1/199.4 MB 1.8 MB/s eta 0:01:31\n",
      "   ------ --------------------------------- 34.6/199.4 MB 1.8 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 35.1/199.4 MB 1.8 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 35.7/199.4 MB 1.9 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 36.2/199.4 MB 1.9 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 36.7/199.4 MB 1.9 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 37.2/199.4 MB 1.9 MB/s eta 0:01:27\n",
      "   ------- -------------------------------- 37.7/199.4 MB 1.9 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 38.3/199.4 MB 1.9 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 38.8/199.4 MB 1.9 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 39.3/199.4 MB 1.9 MB/s eta 0:01:25\n",
      "   ------- -------------------------------- 39.6/199.4 MB 1.9 MB/s eta 0:01:25\n",
      "   -------- ------------------------------- 40.1/199.4 MB 1.9 MB/s eta 0:01:24\n",
      "   -------- ------------------------------- 40.6/199.4 MB 1.9 MB/s eta 0:01:24\n",
      "   -------- ------------------------------- 41.2/199.4 MB 1.9 MB/s eta 0:01:24\n",
      "   -------- ------------------------------- 41.7/199.4 MB 1.9 MB/s eta 0:01:23\n",
      "   -------- ------------------------------- 41.9/199.4 MB 1.9 MB/s eta 0:01:23\n",
      "   -------- ------------------------------- 42.5/199.4 MB 1.9 MB/s eta 0:01:22\n",
      "   -------- ------------------------------- 43.0/199.4 MB 1.9 MB/s eta 0:01:22\n",
      "   -------- ------------------------------- 43.5/199.4 MB 1.9 MB/s eta 0:01:22\n",
      "   -------- ------------------------------- 44.0/199.4 MB 1.9 MB/s eta 0:01:21\n",
      "   -------- ------------------------------- 44.6/199.4 MB 1.9 MB/s eta 0:01:21\n",
      "   --------- ------------------------------ 45.1/199.4 MB 1.9 MB/s eta 0:01:20\n",
      "   --------- ------------------------------ 45.9/199.4 MB 2.0 MB/s eta 0:01:19\n",
      "   --------- ------------------------------ 46.4/199.4 MB 2.0 MB/s eta 0:01:19\n",
      "   --------- ------------------------------ 46.9/199.4 MB 2.0 MB/s eta 0:01:18\n",
      "   --------- ------------------------------ 47.4/199.4 MB 2.0 MB/s eta 0:01:18\n",
      "   --------- ------------------------------ 48.0/199.4 MB 2.0 MB/s eta 0:01:18\n",
      "   --------- ------------------------------ 48.5/199.4 MB 2.0 MB/s eta 0:01:17\n",
      "   --------- ------------------------------ 49.0/199.4 MB 2.0 MB/s eta 0:01:17\n",
      "   --------- ------------------------------ 49.5/199.4 MB 2.0 MB/s eta 0:01:16\n",
      "   --------- ------------------------------ 49.8/199.4 MB 2.0 MB/s eta 0:01:16\n",
      "   ---------- ----------------------------- 50.1/199.4 MB 2.0 MB/s eta 0:01:16\n",
      "   ---------- ----------------------------- 50.6/199.4 MB 2.0 MB/s eta 0:01:16\n",
      "   ---------- ----------------------------- 50.9/199.4 MB 2.0 MB/s eta 0:01:16\n",
      "   ---------- ----------------------------- 51.4/199.4 MB 2.0 MB/s eta 0:01:16\n",
      "   ---------- ----------------------------- 51.9/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 52.2/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 52.4/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 53.0/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 53.2/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 53.5/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 54.0/199.4 MB 2.0 MB/s eta 0:01:15\n",
      "   ---------- ----------------------------- 54.5/199.4 MB 2.0 MB/s eta 0:01:14\n",
      "   ---------- ----------------------------- 54.8/199.4 MB 2.0 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 55.3/199.4 MB 2.0 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 55.6/199.4 MB 2.0 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 56.1/199.4 MB 2.0 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 56.4/199.4 MB 2.0 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 56.9/199.4 MB 2.0 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 57.4/199.4 MB 2.0 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 57.7/199.4 MB 2.0 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 58.2/199.4 MB 2.0 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 58.5/199.4 MB 2.0 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 58.7/199.4 MB 1.9 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 59.2/199.4 MB 2.0 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 59.5/199.4 MB 2.0 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 59.8/199.4 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 60.3/199.4 MB 2.0 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 60.6/199.4 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 61.1/199.4 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 61.3/199.4 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 61.6/199.4 MB 2.0 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 62.1/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 62.4/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 62.7/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 62.9/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 63.4/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 63.7/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 64.0/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 64.0/199.4 MB 2.0 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 64.2/199.4 MB 1.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 64.2/199.4 MB 1.9 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 64.5/199.4 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 64.7/199.4 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 64.7/199.4 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------- -------------------------- 65.0/199.4 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------- -------------------------- 65.3/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 65.3/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 65.5/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 65.8/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 66.1/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 66.1/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 66.3/199.4 MB 1.9 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 66.6/199.4 MB 1.8 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 66.8/199.4 MB 1.8 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 67.1/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 67.4/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 67.4/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 67.6/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 68.2/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 68.4/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 68.9/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   ------------- -------------------------- 69.5/199.4 MB 1.8 MB/s eta 0:01:12\n",
      "   ------------- -------------------------- 69.7/199.4 MB 1.8 MB/s eta 0:01:13\n",
      "   -------------- ------------------------- 70.3/199.4 MB 1.8 MB/s eta 0:01:12\n",
      "   -------------- ------------------------- 70.5/199.4 MB 1.8 MB/s eta 0:01:12\n",
      "   -------------- ------------------------- 71.0/199.4 MB 1.8 MB/s eta 0:01:12\n",
      "   -------------- ------------------------- 71.3/199.4 MB 1.8 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 71.8/199.4 MB 1.8 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 72.1/199.4 MB 1.8 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 72.6/199.4 MB 1.8 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 72.9/199.4 MB 1.8 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 73.1/199.4 MB 1.8 MB/s eta 0:01:11\n",
      "   -------------- ------------------------- 73.7/199.4 MB 1.8 MB/s eta 0:01:10\n",
      "   -------------- ------------------------- 73.9/199.4 MB 1.8 MB/s eta 0:01:10\n",
      "   -------------- ------------------------- 74.2/199.4 MB 1.8 MB/s eta 0:01:10\n",
      "   -------------- ------------------------- 74.7/199.4 MB 1.8 MB/s eta 0:01:10\n",
      "   --------------- ------------------------ 75.0/199.4 MB 1.8 MB/s eta 0:01:09\n",
      "   --------------- ------------------------ 75.2/199.4 MB 1.8 MB/s eta 0:01:09\n",
      "   --------------- ------------------------ 75.8/199.4 MB 1.8 MB/s eta 0:01:09\n",
      "   --------------- ------------------------ 76.0/199.4 MB 1.8 MB/s eta 0:01:09\n",
      "   --------------- ------------------------ 76.5/199.4 MB 1.8 MB/s eta 0:01:08\n",
      "   --------------- ------------------------ 77.1/199.4 MB 1.8 MB/s eta 0:01:08\n",
      "   --------------- ------------------------ 77.6/199.4 MB 1.8 MB/s eta 0:01:07\n",
      "   --------------- ------------------------ 77.9/199.4 MB 1.8 MB/s eta 0:01:07\n",
      "   --------------- ------------------------ 78.4/199.4 MB 1.8 MB/s eta 0:01:07\n",
      "   --------------- ------------------------ 78.9/199.4 MB 1.8 MB/s eta 0:01:06\n",
      "   --------------- ------------------------ 79.4/199.4 MB 1.8 MB/s eta 0:01:06\n",
      "   --------------- ------------------------ 79.7/199.4 MB 1.8 MB/s eta 0:01:06\n",
      "   ---------------- ----------------------- 80.2/199.4 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------- ----------------------- 80.7/199.4 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------- ----------------------- 81.0/199.4 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------- ----------------------- 81.5/199.4 MB 1.8 MB/s eta 0:01:05\n",
      "   ---------------- ----------------------- 82.1/199.4 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 82.6/199.4 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 82.8/199.4 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 83.4/199.4 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 83.6/199.4 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 84.1/199.4 MB 1.8 MB/s eta 0:01:04\n",
      "   ---------------- ----------------------- 84.7/199.4 MB 1.8 MB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 85.2/199.4 MB 1.8 MB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 85.7/199.4 MB 1.8 MB/s eta 0:01:03\n",
      "   ----------------- ---------------------- 86.2/199.4 MB 1.8 MB/s eta 0:01:02\n",
      "   ----------------- ---------------------- 86.8/199.4 MB 1.8 MB/s eta 0:01:02\n",
      "   ----------------- ---------------------- 87.3/199.4 MB 1.8 MB/s eta 0:01:02\n",
      "   ----------------- ---------------------- 87.6/199.4 MB 1.8 MB/s eta 0:01:02\n",
      "   ----------------- ---------------------- 88.1/199.4 MB 1.8 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 88.6/199.4 MB 1.8 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 88.9/199.4 MB 1.8 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 89.7/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 90.2/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 90.4/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 90.7/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 91.2/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 91.5/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 92.0/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 92.5/199.4 MB 1.8 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 93.1/199.4 MB 1.8 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 93.3/199.4 MB 1.8 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 93.6/199.4 MB 1.8 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 94.1/199.4 MB 1.8 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 94.6/199.4 MB 1.8 MB/s eta 0:00:59\n",
      "   ------------------- -------------------- 95.2/199.4 MB 1.8 MB/s eta 0:00:58\n",
      "   ------------------- -------------------- 95.7/199.4 MB 1.8 MB/s eta 0:00:58\n",
      "   ------------------- -------------------- 95.9/199.4 MB 1.8 MB/s eta 0:00:58\n",
      "   ------------------- -------------------- 96.5/199.4 MB 1.8 MB/s eta 0:00:58\n",
      "   ------------------- -------------------- 97.0/199.4 MB 1.8 MB/s eta 0:00:58\n",
      "   ------------------- -------------------- 97.5/199.4 MB 1.8 MB/s eta 0:00:57\n",
      "   ------------------- -------------------- 97.8/199.4 MB 1.8 MB/s eta 0:00:57\n",
      "   ------------------- -------------------- 98.6/199.4 MB 1.8 MB/s eta 0:00:57\n",
      "   ------------------- -------------------- 99.1/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   ------------------- -------------------- 99.4/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 99.9/199.4 MB 1.8 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 100.4/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 100.9/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 101.4/199.4 MB 1.8 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 101.7/199.4 MB 1.8 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 102.0/199.4 MB 1.8 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 102.2/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 102.5/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 102.5/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 102.5/199.4 MB 1.8 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 102.8/199.4 MB 1.7 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 103.0/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 103.3/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 103.3/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 103.5/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 103.8/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 104.3/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   -------------------- ------------------- 104.3/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 104.9/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 105.1/199.4 MB 1.7 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 105.4/199.4 MB 1.7 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 105.6/199.4 MB 1.7 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 105.9/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 106.2/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 106.2/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 106.4/199.4 MB 1.7 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 107.0/199.4 MB 1.6 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 107.2/199.4 MB 1.6 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 107.7/199.4 MB 1.6 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 108.3/199.4 MB 1.7 MB/s eta 0:00:56\n",
      "   --------------------- ------------------ 108.8/199.4 MB 1.7 MB/s eta 0:00:55\n",
      "   --------------------- ------------------ 109.3/199.4 MB 1.7 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 109.8/199.4 MB 1.7 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 110.4/199.4 MB 1.7 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 110.9/199.4 MB 1.7 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 111.7/199.4 MB 1.7 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 112.2/199.4 MB 1.7 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 112.7/199.4 MB 1.7 MB/s eta 0:00:51\n",
      "   ---------------------- ----------------- 113.2/199.4 MB 1.7 MB/s eta 0:00:51\n",
      "   ---------------------- ----------------- 113.8/199.4 MB 1.7 MB/s eta 0:00:50\n",
      "   ---------------------- ----------------- 114.0/199.4 MB 1.7 MB/s eta 0:00:50\n",
      "   ---------------------- ----------------- 114.6/199.4 MB 1.7 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 115.1/199.4 MB 1.7 MB/s eta 0:00:49\n",
      "   ----------------------- ---------------- 115.6/199.4 MB 1.7 MB/s eta 0:00:49\n",
      "   ----------------------- ---------------- 116.1/199.4 MB 1.7 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 116.7/199.4 MB 1.8 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 117.2/199.4 MB 1.8 MB/s eta 0:00:47\n",
      "   ----------------------- ---------------- 117.7/199.4 MB 1.8 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 118.5/199.4 MB 1.8 MB/s eta 0:00:45\n",
      "   ----------------------- ---------------- 119.0/199.4 MB 1.8 MB/s eta 0:00:45\n",
      "   ----------------------- ---------------- 119.5/199.4 MB 1.8 MB/s eta 0:00:44\n",
      "   ------------------------ --------------- 119.8/199.4 MB 1.8 MB/s eta 0:00:44\n",
      "   ------------------------ --------------- 120.6/199.4 MB 1.9 MB/s eta 0:00:43\n",
      "   ------------------------ --------------- 121.1/199.4 MB 1.9 MB/s eta 0:00:42\n",
      "   ------------------------ --------------- 121.6/199.4 MB 1.9 MB/s eta 0:00:42\n",
      "   ------------------------ --------------- 122.2/199.4 MB 1.9 MB/s eta 0:00:41\n",
      "   ------------------------ --------------- 122.7/199.4 MB 1.9 MB/s eta 0:00:41\n",
      "   ------------------------ --------------- 123.2/199.4 MB 1.9 MB/s eta 0:00:40\n",
      "   ------------------------ --------------- 123.7/199.4 MB 1.9 MB/s eta 0:00:40\n",
      "   ------------------------ --------------- 124.3/199.4 MB 1.9 MB/s eta 0:00:40\n",
      "   ------------------------- -------------- 124.8/199.4 MB 1.9 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 125.0/199.4 MB 1.9 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 125.6/199.4 MB 1.9 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 126.1/199.4 MB 2.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 126.4/199.4 MB 2.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 126.9/199.4 MB 2.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 127.1/199.4 MB 2.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 127.9/199.4 MB 2.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 128.5/199.4 MB 2.0 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 129.0/199.4 MB 2.0 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 129.5/199.4 MB 2.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 129.8/199.4 MB 2.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 130.3/199.4 MB 2.0 MB/s eta 0:00:35\n",
      "   -------------------------- ------------- 130.8/199.4 MB 2.0 MB/s eta 0:00:35\n",
      "   -------------------------- ------------- 131.3/199.4 MB 2.0 MB/s eta 0:00:35\n",
      "   -------------------------- ------------- 131.9/199.4 MB 2.0 MB/s eta 0:00:34\n",
      "   -------------------------- ------------- 132.4/199.4 MB 2.0 MB/s eta 0:00:34\n",
      "   -------------------------- ------------- 133.2/199.4 MB 2.0 MB/s eta 0:00:33\n",
      "   -------------------------- ------------- 133.7/199.4 MB 2.0 MB/s eta 0:00:33\n",
      "   -------------------------- ------------- 134.2/199.4 MB 2.0 MB/s eta 0:00:33\n",
      "   -------------------------- ------------- 134.5/199.4 MB 2.0 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 135.0/199.4 MB 2.0 MB/s eta 0:00:32\n",
      "   --------------------------- ------------ 135.5/199.4 MB 2.0 MB/s eta 0:00:32\n",
      "   --------------------------- ------------ 136.1/199.4 MB 2.0 MB/s eta 0:00:32\n",
      "   --------------------------- ------------ 136.6/199.4 MB 2.0 MB/s eta 0:00:31\n",
      "   --------------------------- ------------ 137.1/199.4 MB 2.1 MB/s eta 0:00:31\n",
      "   --------------------------- ------------ 137.9/199.4 MB 2.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 138.4/199.4 MB 2.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 138.9/199.4 MB 2.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 139.5/199.4 MB 2.1 MB/s eta 0:00:30\n",
      "   ---------------------------- ----------- 140.0/199.4 MB 2.1 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 140.5/199.4 MB 2.1 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 141.0/199.4 MB 2.1 MB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 141.6/199.4 MB 2.1 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 142.1/199.4 MB 2.1 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 142.6/199.4 MB 2.1 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 143.4/199.4 MB 2.1 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 143.9/199.4 MB 2.1 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 144.4/199.4 MB 2.1 MB/s eta 0:00:27\n",
      "   ----------------------------- ---------- 145.0/199.4 MB 2.1 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 145.8/199.4 MB 2.1 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 146.3/199.4 MB 2.1 MB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 146.8/199.4 MB 2.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 147.3/199.4 MB 2.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 147.8/199.4 MB 2.1 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 148.4/199.4 MB 2.1 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 148.9/199.4 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 149.7/199.4 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 150.2/199.4 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 150.7/199.4 MB 2.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 151.3/199.4 MB 2.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 151.8/199.4 MB 2.1 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 152.6/199.4 MB 2.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 152.8/199.4 MB 2.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 153.4/199.4 MB 2.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 154.1/199.4 MB 2.2 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 154.9/199.4 MB 2.2 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 155.5/199.4 MB 2.2 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 156.0/199.4 MB 2.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 156.5/199.4 MB 2.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 157.0/199.4 MB 2.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 157.3/199.4 MB 2.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 157.8/199.4 MB 2.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 158.3/199.4 MB 2.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 158.6/199.4 MB 2.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 159.1/199.4 MB 2.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 159.4/199.4 MB 2.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 159.9/199.4 MB 2.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 160.4/199.4 MB 2.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 160.7/199.4 MB 2.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 161.2/199.4 MB 2.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 161.7/199.4 MB 2.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 162.3/199.4 MB 2.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 162.5/199.4 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 163.1/199.4 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 163.6/199.4 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 164.1/199.4 MB 2.2 MB/s eta 0:00:17\n",
      "   --------------------------------- ------ 164.9/199.4 MB 2.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 165.4/199.4 MB 2.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 165.7/199.4 MB 2.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 166.2/199.4 MB 2.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 166.7/199.4 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 167.5/199.4 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 167.8/199.4 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 168.3/199.4 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 168.8/199.4 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 169.6/199.4 MB 2.3 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 170.1/199.4 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 170.7/199.4 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 171.2/199.4 MB 2.3 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 172.0/199.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 172.5/199.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 172.8/199.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 173.3/199.4 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 174.1/199.4 MB 2.3 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 174.6/199.4 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 174.6/199.4 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 175.4/199.4 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 175.9/199.4 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 176.4/199.4 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 176.7/199.4 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 177.2/199.4 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 177.7/199.4 MB 2.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 178.0/199.4 MB 2.4 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 178.5/199.4 MB 2.4 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 179.0/199.4 MB 2.4 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 179.6/199.4 MB 2.4 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 180.4/199.4 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 180.9/199.4 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 181.4/199.4 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 181.9/199.4 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 182.5/199.4 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 183.0/199.4 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 183.5/199.4 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 184.0/199.4 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 184.5/199.4 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 185.3/199.4 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 185.9/199.4 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 186.4/199.4 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 186.9/199.4 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 187.4/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 187.7/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.0/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 188.5/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 189.0/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 189.3/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 189.8/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 189.8/199.4 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 190.3/199.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 190.8/199.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.1/199.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.4/199.4 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.6/199.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.6/199.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 191.9/199.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.2/199.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.4/199.4 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 192.9/199.4 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.2/199.4 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.7/199.4 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 194.0/199.4 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.5/199.4 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  194.8/199.4 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  195.0/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.6/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.8/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.3/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.6/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.9/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  197.1/199.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  197.4/199.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.7/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.9/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.2/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.4/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.4/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.7/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.0/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.19.1-cp38-cp38-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.7.5-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.5 MB 3.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.6/7.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.6/7.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.7/7.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.5/7.5 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.0/7.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.5/7.5 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.0/7.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.8/7.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.3/7.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp38-cp38-win_amd64.whl (55 kB)\n",
      "Downloading pillow-10.4.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.2 MB 3.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.0/6.2 MB 3.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.3/6.2 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.2 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 2.4/6.2 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 2.4/6.2 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.9/6.2 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 3.1/6.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.9/6.2 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.2/6.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.7/6.2 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 5.2/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 1.3 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, pyparsing, pillow, networkx, kiwisolver, fonttools, cycler, contourpy, torch, matplotlib, torchvision\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.55.1 kiwisolver-1.4.7 matplotlib-3.7.5 mpmath-1.3.0 networkx-3.1 pillow-10.4.0 pyparsing-3.1.4 sympy-1.13.3 torch-2.4.1 torchvision-0.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21583031-a355-45d0-a008-26ca11f13eed",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "* Perform sentimental analysis on social media posts using BERT(Bidirectional Encoder Representations from Transformers). We analyze each post (positive, negative, or neutral) using dataset, training a BERT model to classify the sentiments accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1b1d8-066c-4e4e-b9f9-cb0953e0cc25",
   "metadata": {},
   "source": [
    "### Imporing libraries and Configuring Dependencies\n",
    "\n",
    "* Transformers: For BERT Tokenizer and model\n",
    "* Pandas and Numpy for data manipulation\n",
    "* Torch Pytorch library for deep learning\n",
    "* Sklearn for model evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a362b-948d-44f7-95d5-3d415e62825c",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing Dataset\n",
    "\n",
    "* load data with pandas and remove unnecessary cols\n",
    "* We convert the target column to binary values for sentiment (0: Negative, 1: Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f37c679-6316-4cae-839b-84f2c93bbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['target', 'ids', 'date', 'flag', 'user','text']\n",
    "df1 = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', names=columns)\n",
    "\n",
    "df = df1.sample(n=3000, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5383e1e2-4b3c-41de-8839-98fc1fc41682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only necessary cols\n",
    "\n",
    "df = df[['target', 'text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e8be8d6-bdcc-40bb-a88e-1b9306170ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541200</th>\n",
       "      <td>0</td>\n",
       "      <td>@chrishasboobs AHHH I HOPE YOUR OK!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0</td>\n",
       "      <td>@misstoriblack cool , i have no tweet apps  fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766711</th>\n",
       "      <td>0</td>\n",
       "      <td>@TiannaChaos i know  just family drama. its la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285055</th>\n",
       "      <td>0</td>\n",
       "      <td>School email won't open  and I have geography ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705995</th>\n",
       "      <td>0</td>\n",
       "      <td>upper airways problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text\n",
       "541200       0             @chrishasboobs AHHH I HOPE YOUR OK!!! \n",
       "750          0  @misstoriblack cool , i have no tweet apps  fo...\n",
       "766711       0  @TiannaChaos i know  just family drama. its la...\n",
       "285055       0  School email won't open  and I have geography ...\n",
       "705995       0                             upper airways problem "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b4edec-c512-4520-80d1-a7511e3ce4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping target labels: 0 -> Negative, 4 -> Positive\n",
    "df['target'] = df['target'].map({0:0, 4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec12422-fde6-4d9b-9e3d-1edd9ed7a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    1513\n",
      "0    1487\n",
      "Name: count, dtype: int64\n",
      "        target                                               text\n",
      "541200       0             @chrishasboobs AHHH I HOPE YOUR OK!!! \n",
      "750          0  @misstoriblack cool , i have no tweet apps  fo...\n",
      "766711       0  @TiannaChaos i know  just family drama. its la...\n",
      "285055       0  School email won't open  and I have geography ...\n",
      "705995       0                             upper airways problem \n"
     ]
    }
   ],
   "source": [
    "# Check dataset distribution\n",
    "\n",
    "print(df['target'].value_counts())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a8220-efc7-40a6-a024-3d3031982394",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "* Dataset contains text and sentiment columns\n",
    "* Basic Stats reveal the distribution as positive, negative, and neutral sentiments\n",
    "* Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc698c26-1674-4490-99e0-266fd89af723",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "\n",
    "* Text Cleaning: Removing URLs, mentions, and special characters\n",
    "* Tokenization: BERT's tokenizer to convert text into tokens\n",
    "* Padding and Truncation: Ensure Uniform sequence length\n",
    "* Splitting: Divide data into training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9cc618b-9862-4f4a-9243-5060ec8d6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Loading the bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # Remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text) # Remove mentions\n",
    "    text = re.sub(r\"#\\w+\", \"\", text) # Remove Hashtags\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text) # Remove Special Characters\n",
    "\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb9e6684-7ecf-4dc5-8c19-6695df927ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d58ac81-376f-4162-8fa7-fbdbe4fca8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode text using BERT Tokenizer\n",
    "\n",
    "def tokenize_data(texts, labels, max_len=128):\n",
    "    encodings=tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "    labels = torch.tensor(labels.values)\n",
    "    return encodings, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "562abbf9-7cca-4e2e-ad94-e6ff9f09241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"text\"], df[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "train_encodings, train_labels = tokenize_data(train_texts, train_labels)\n",
    "test_encodings, test_labels = tokenize_data(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4d0dd-1a6b-473d-94fc-43c518dde39f",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "* Use a pre-trained BERT model with a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e404673a-739b-496b-a7d4-a89cae5e8148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10b0a0c8-fcc4-4973-9617-b30f8ff008e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83bd1e523d848ecac83b73450e8b590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/bert-base-uncased/68d45e234eb4a928074dfd868cead0219ab85354cc53d20e772753c6bb9169d3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1733561948&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzU2MTk0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9iZXJ0LWJhc2UtdW5jYXNlZC82OGQ0NWUyMzRlYjRhOTI4MDc0ZGZkODY4Y2VhZDAyMTlhYjg1MzU0Y2M1M2QyMGU3NzI3NTNjNmJiOTE2OWQzP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=KMag0BbZK7BE91JWz27c%7EFz4t3CMA4dij7OOShEFq6kuq0W6FpCixX6IDz%7EVc0gLgZouzmLSB--yizplhKJjqtEO9M6-rAI-iVRZQE6WtNyEzZVdDx2KfEiSqsynO9S8KeJAkW8148euVzq77YMDTOKrYAKa5vb6025CeFXU%7EA2IepwxEoVeIb1f-j2xj3AgAGyISsCKyPNQTPLjUdqoWy8OO0j%7EEiHE132QXiCu8GN8kKAn%7EADoGhvDMLD6D-Xyls1gXU6ZLfEyY707H3buBR-6HLordgvQbB9ieS2LfBCUm74Gf-NNoGPVWCsmclFKx4vq9kyewGnqIb6RKGTrdg__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9895f76421b34054b01cff17833349e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  93%|#########2| 409M/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading BERT model\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425410e7-3a10-4c66-9d25-b65bd554a86d",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "* Use the tokenized data to train the BERT model\n",
    "* Creating a custom Class for our Dataset\n",
    "* Creating Data Loaders since we're using Pytorch\n",
    "* Move model to appropriate device\n",
    "* Define the optimizer (AdamW)\n",
    "* Create the training loop with epochs, which will train the model and also display the loss\n",
    "* tqdm is used to show progess of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "667468c5-b08f-423b-8319-ad069ed16067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# create custom dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key : val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ce6c991-b018-43ea-98c2-8fccb4e60753",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "test_dataset = SentimentDataset(test_encodings, test_labels)\n",
    "\n",
    "# Creating dataloaders as we're using Pytorch\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1863b727-5a96-47dd-a716-9c53c18f3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to appropriate device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29ec224d-3660-41cf-b81d-a53b878abb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a43e3ca-513c-435e-acf7-49baece93acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 150/150 [18:06<00:00,  7.24s/it, loss=0.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5178608155250549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 150/150 [17:32<00:00,  7.02s/it, loss=0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2711653878291448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 150/150 [5:31:12<00:00, 132.49s/it, loss=0.0038]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0993164998300684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "        # Move data to appropriate device\n",
    "        batch = {key: val.to(device) for key, val in batch.items()}\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"Epoch {epoch + 1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4563b-d7be-4bdb-a89e-e248478744d5",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "* Evaluate the model metrics like accuracy, precision, recall, and F1-Score.\n",
    "* Confusion Matrix: To visualize model performance across classes.\n",
    "* Classification Report: Shows precision, recall, and F1-Score per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64d60c70-bc30-446d-92fe-e130e538b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4065c951-6863-49e3-ba94-f449121aee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import torch\n",
    "\n",
    "# # Evaluation Loop\n",
    "\n",
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_loader:\n",
    "#         # Move batch to appropriate device\n",
    "#         batch = {key: val.to(device) for key, val in batch.items()}\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(**batch)\n",
    "\n",
    "#         # Predictions and Labels\n",
    "#         preds = torch.argmax(outputs.logits, dim=1).cpu().numpy() # Move predictions to CPU for metrics\n",
    "\n",
    "#         labels = batch['labels'].cpu().numpy() # Now move labels\n",
    "\n",
    "#         all_preds.extend(preds)\n",
    "#         all_labels.extend(labels)\n",
    "\n",
    "# # Generate the classification report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "200d1eb8-6938-4161-bfb4-433092f40be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       285\n",
      "           1       0.85      0.72      0.78       315\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.79      0.79      0.78       600\n",
      "weighted avg       0.79      0.79      0.78       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf7cde-90cc-4551-b54b-55857d3ff08f",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "* High recall for positive and negative classes\n",
    "* Some confusion netural sentiments, indicating a need for more balanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50624450-581f-40cb-a73d-9798c8a4c072",
   "metadata": {},
   "source": [
    "### Save Model and Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbfd9fe0-4a4b-4e48-9097-46526770b7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentiment_model\\\\tokenizer_config.json',\n",
       " 'sentiment_model\\\\special_tokens_map.json',\n",
       " 'sentiment_model\\\\vocab.txt',\n",
       " 'sentiment_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"sentiment_model\")\n",
    "tokenizer.save_pretrained(\"sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32cc21a0-6df8-49e1-965c-9fb0cccda2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from fastapi) (4.11.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading pydantic_core-2.27.1-cp38-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.0)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp38-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 578.7 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 578.7 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.8/2.0 MB 644.9 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/2.0 MB 708.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 737.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 783.9 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 783.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 832.4 kB/s eta 0:00:00\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: typing-extensions, uvicorn, pydantic-core, annotated-types, starlette, pydantic, fastapi\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "Successfully installed annotated-types-0.7.0 fastapi-0.115.6 pydantic-2.10.3 pydantic-core-2.27.1 starlette-0.41.3 typing-extensions-4.12.2 uvicorn-0.32.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.10.0 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.10.0 requires tensorflow-io-gcs-filesystem>=0.23.1, which is not installed.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "973b3fdb-039e-4ea9-8c59-79875fe9eea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\ahmed\\miniconda3\\envs\\bert_env\\lib\\site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7697d560-b3d7-4f09-9529-0eacff6b96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [13580]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:5085 - \"GET /predict HTTP/1.1\" 405 Method Not Allowed\n",
      "INFO:     127.0.0.1:5086 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:5530 - \"GET /predict HTTP/1.1\" 405 Method Not Allowed\n",
      "INFO:     127.0.0.1:5826 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:5846 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:5848 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:5850 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [13580]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m server \u001b[38;5;241m=\u001b[39m Server(config)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Start the server\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\site-packages\\uvicorn\\server.py:65\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\site-packages\\nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\asyncio\\events.py:81\u001b[0m, in \u001b[0;36mHandle._run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\asyncio\\tasks.py:360\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\asyncio\\tasks.py:280\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\site-packages\\uvicorn\\server.py:69\u001b[0m, in \u001b[0;36mServer.serve\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture_signals():\n\u001b[1;32m---> 69\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serve(sockets)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\contextlib.py:120\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\bert_env\\lib\\site-packages\\uvicorn\\server.py:332\u001b[0m, in \u001b[0;36mServer.capture_signals\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# If we did gracefully shut down due to a signal, try to\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# trigger the expected behaviour now; multiple signals would be\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m captured_signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captured_signals):\n\u001b[1;32m--> 332\u001b[0m     \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_signal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "from uvicorn import Config, Server\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "app = FastAPI()  # initializing FastAPI\n",
    "\n",
    "# Load saved model\n",
    "model = BertForSequenceClassification.from_pretrained(\"sentiment_model\").to('cpu')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"sentiment_model\")\n",
    "\n",
    "# Define request structure\n",
    "class SentimentRequest(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"Welcome to the Sentiment Analysis API! Use POST /predict to analyze sentiment.\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_sentiment(request: SentimentRequest):\n",
    "    inputs = tokenizer(request.text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(\"cpu\")\n",
    "    outputs = model(**inputs)\n",
    "    sentiment = torch.argmax(outputs.logits).item()\n",
    "    sentiment_label = \"Positive\" if sentiment == 1 else \"Negative\"\n",
    "    return {\"sentiment\": sentiment_label}\n",
    "\n",
    "# Allow the event loop to run inside Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the FastAPI app\n",
    "config = Config(app=app, host=\"127.0.0.1\", port=8000, log_level=\"info\")\n",
    "server = Server(config)\n",
    "\n",
    "# Start the server\n",
    "server.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
